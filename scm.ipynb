{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "import dowhy\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073fc61-2232-41f5-9884-e4d3d0f9e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_causal.csv') # Change file name and path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab89d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One potential DAG model for the transport system\n",
    "causal_graph = \"\"\"digraph {\n",
    "    \n",
    "    \"Particle Density\" -> \"Hydraulic Conductivity\";\n",
    "    \"Particle Density\"-> Dispersivity;\n",
    "    \"Particle Density\" -> \"Adsorption Coefficient\";\n",
    "    \"Particle Density\" -> \"Type-1 Sorption Fraction\";  \n",
    "    \n",
    "    \"Porosity\" -> \"Hydraulic Conductivity\";\n",
    "    \"Porosity\"-> Dispersivity;\n",
    "    \"Porosity\" -> \"Adsorption Coefficient\";\n",
    "    \"Porosity\" -> \"Type-1 Sorption Fraction\";         \n",
    "    \n",
    "    \"Degree of Saturation\" -> Dispersivity;   \n",
    "    \"Degree of Saturation\" -> \"Type-1 Sorption Fraction\";    \n",
    "    Distance -> Dispersivity;    \n",
    "    Concentration -> \"Type-2 Sorption Reaction Rate\";\n",
    "    \n",
    "    \"Ponded Water Depth\" -> \"Relative Velocity\";    \n",
    "    Flux -> \"Relative Velocity\";\n",
    "    \"Type-1 Sorption Fraction\" -> \"Relative Velocity\";        \n",
    "    \"Degree of Saturation\" -> \"Relative Velocity\";\n",
    "    Distance ->  \"Relative Velocity\"; \n",
    "    Concentration -> \"Relative Velocity\";\n",
    "    Horizontal -> \"Relative Velocity\";\n",
    "    \"Adsorption Coefficient\" -> \"Relative Velocity\";        \n",
    "    \"Hydraulic Conductivity\" -> \"Relative Velocity\";\n",
    "    Dispersivity-> \"Relative Velocity\";\n",
    "    \"Type-2 Sorption Reaction Rate\"-> \"Relative Velocity\";\n",
    "    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a7db8-a02f-4992-abf7-6a92e4470bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydot_graph = pydot.graph_from_dot_data(causal_graph.replace(\"\\n\", \" \"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240e45b-9f31-4af5-acc1-a034b63e74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.drawing.nx_pydot.from_pydot(pydot_graph)\n",
    "\n",
    "# Extract all edge pairs\n",
    "edge_pairs = list(nx_graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ad798-a4f1-4956-a638-5491efb10b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafd0ca-f0e8-4316-8170-05cc91a9d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Ponded Water': 'Ponded Water Depth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b460739-0789-432e-8dae-f9cb5cab64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_model(treatment,outcome,graph,df):\n",
    "    model = dowhy.CausalModel(data = df,\n",
    "                        treatment = treatment,\n",
    "                        outcome = outcome,\n",
    "                        graph = graph)\n",
    "    \n",
    "    modifiers = model.get_effect_modifiers()\n",
    "    confounders = model.get_common_causes()   \n",
    "\n",
    "    estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "    backdoor_var = estimand.backdoor_variables\n",
    "    \n",
    "    #  Linear\n",
    "    estimate_li = model.estimate_effect(estimand,method_name = \"backdoor.linear_regression\", method_params = None, confidence_intervals = True)\n",
    "    \n",
    "    print(treatment,outcome,\"############### Now refuting: Random Common Cause (Linear)#######################\")\n",
    "    res_random_li=model.refute_estimate(estimand,estimate_li, method_name=\"random_common_cause\")    \n",
    "    print(treatment,outcome,\"############### Now refuting: Add Unobserved Common Cause (Linear)######################\")\n",
    "    res_unobserved_li=model.refute_estimate(estimand, estimate_li, method_name=\"add_unobserved_common_cause\",\n",
    "                                         confounders_effect_on_treatment=\"binary_flip\", confounders_effect_on_outcome=\"linear\",\n",
    "                                        effect_strength_on_treatment=0.01, effect_strength_on_outcome=0.02)\n",
    "    print(treatment,outcome,\"############### Now refuting: Placebo (Linear)##############################\")\n",
    "    res_placebo_li=model.refute_estimate(estimand, estimate_li, method_name=\"placebo_treatment_refuter\",placebo_type=\"permute\")\n",
    "    li_res = [estimate_li.value, estimate_li.get_confidence_intervals(),res_random_li,res_unobserved_li,res_placebo_li]\n",
    "\n",
    "    #  DML\n",
    "    if len(confounders)>0 or len(modifiers)>0:     \n",
    "        \n",
    "        est_nonparam = CausalForestDML(model_y=GradientBoostingRegressor(), model_t=GradientBoostingRegressor(),random_state=12)\n",
    "\n",
    "        Y = df[outcome].values\n",
    "        T = df[treatment].values\n",
    "\n",
    "        args = [Y, T]\n",
    "\n",
    "\n",
    "        if len(modifiers)== 0:\n",
    "                        \n",
    "            print('Special case: NO Effect Modifier!')\n",
    "            kwargs = {'inference':'auto'}\n",
    "            X = df[confounders].values\n",
    "            kwargs['X'] = X\n",
    "            W = None\n",
    "\n",
    "            # Here in the special case, we use raw EconML interface instead of DoWhy wrapper or EconML wrapper in either package to avoid confusion\n",
    "            est_nonparam.fit(*args, **kwargs)\n",
    "            estimated_ate = te_pred.mean()\n",
    "            te_pred = est_nonparam.effect(X)\n",
    "            estimated_ate_ci = (est_nonparam.effect_interval(X)[0].mean(),est_nonparam.effect_interval(X)[1].mean())\n",
    "\n",
    "            print(treatment,outcome,\"############### NO DML REFUTATION!#######################\")\n",
    "            \n",
    "            res_random_dml,res_unobserved_dml,res_placebo_dml = None,None,None   \n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            print('Ordinary case: has effect modifier and confounders.')\n",
    "            \n",
    "            estimate_dml = model.estimate_effect(estimand, method_name=\"backdoor.econml.dml.CausalForestDML\",\n",
    "                                 confidence_intervals=True,\n",
    "                                method_params={\"init_params\":{'model_y':GradientBoostingRegressor(),\n",
    "                                                              'model_t': GradientBoostingRegressor()},\n",
    "                                               \"fit_params\":{}})      \n",
    "            \n",
    "            estimated_ate = estimate_dml.value\n",
    "            te_pred = estimate_dml.cate_estimates\n",
    "            estimated_ate_ci = estimate_dml.get_confidence_intervals()   \n",
    "\n",
    "            print(treatment,outcome,\"############### Now refuting: Random Common Cause (DML)##################\")\n",
    "            res_random_dml = model.refute_estimate(estimand, estimate_dml, method_name=\"random_common_cause\")\n",
    "\n",
    "            print(treatment,outcome,\"############### Now refuting: Add Unobserved Common Cause (DML)##################\")\n",
    "            res_unobserved_dml =model.refute_estimate(estimand, estimate_dml, method_name=\"add_unobserved_common_cause\",\n",
    "                                                 confounders_effect_on_treatment=\"binary_flip\", confounders_effect_on_outcome=\"linear\",\n",
    "                                                effect_strength_on_treatment=0.01, effect_strength_on_outcome=0.02)\n",
    "\n",
    "            print(treatment,outcome,\"############### Now refuting: Placebo (DML)##############################\")\n",
    "            res_placebo_dml = model.refute_estimate(estimand, estimate_dml, method_name=\"placebo_treatment_refuter\", placebo_type=\"permute\")\n",
    "            \n",
    "\n",
    "\n",
    "        dml_res = [estimated_ate, te_pred,estimated_ate_ci,res_random_dml,res_unobserved_dml,res_placebo_dml]        \n",
    "\n",
    "    else:\n",
    "        dml_res = None\n",
    "\n",
    "    return li_res,dml_res,modifiers,confounders, backdoor_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee39f3-4296-4054-be2a-5b03013da6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbadb40-1861-4108-b86a-01c93661d119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pair in edge_pairs[:]:\n",
    "    results_full.append(causal_model(*pair,causal_graph,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5e52a-1ef5-4268-8274-8a8e4afd0ae1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pair in edge_pairs[20:]:\n",
    "    results_full.append(causal_model(*pair,causal_graph,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res=pd.DataFrame(columns = \n",
    "                         ['treatment','outcome',\n",
    "                          'ate_li','ci_li',\n",
    "                          'rand_li','rand_li-p-val','rand_li-is_statistically_significant',\n",
    "                          'unobserved_li','placebo_li','li-pl-p-val','li-pl_is_statistically_significant',\n",
    "                          'ate_dml','ate2_dml','ci_dml',\n",
    "                          'rand_dml','rand_dml-p-val','rand_dml-is_statistically_significant',\n",
    "                          'unobserved_dml','placebo_dml','dml_pl_p_val','dml_pl_is_statistically_significant',\n",
    "                          'modifiers','confounders','backdoor_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e43a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['treatment'] = [ele[0] for ele in edge_pairs]\n",
    "df_res['outcome'] = [ele[1] for ele in edge_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['ate_li'] = [x[0][0] for x in results_full]\n",
    "df_res['ci_li'] = [x[0][1] for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b33d27-97d8-477e-9039-3946b1f2e5d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res['rand_li'] = [x[0][2].new_effect for x in results_full]\n",
    "df_res['rand_li-p-val'] = [x[0][2].refutation_result['p_value'] for x in results_full]\n",
    "df_res['rand_li-is_statistically_significant'] = [x[0][2].refutation_result['is_statistically_significant'] for x in results_full]\n",
    "df_res['unobserved_li'] = [x[0][3].new_effect for x in results_full]\n",
    "df_res['placebo_li'] = [x[0][4].new_effect for x in results_full]\n",
    "df_res['li-pl-p-val'] = [x[0][4].refutation_result['p_value'] for x in results_full]\n",
    "df_res['li-pl_is_statistically_significant'] = [x[0][4].refutation_result['is_statistically_significant'] for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ec397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['ate_dml'] = [x[1][0] if x[1] else None for x in results_full]\n",
    "df_res['ate2_dml'] = [x[1][1] if x[1] else None for x in results_full]\n",
    "df_res['ci_dml'] = [x[1][2] if x[1] else None for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b6991-8fba-485a-9dbf-8ea72865d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['rand_dml'] = [x[1][3].new_effect if x[1] else None for x in results_full]\n",
    "df_res['rand_dml-p-val'] = [x[1][3].refutation_result['p_value'] if x[1] else None for x in results_full]\n",
    "df_res['rand_dml-is_statistically_significant'] = [x[1][3].refutation_result['is_statistically_significant'] if x[1] else None for x in results_full]\n",
    "df_res['unobserved_dml'] = [x[1][4].new_effect if x[1] else None for x in results_full]\n",
    "df_res['placebo_dml'] = [x[1][5].new_effect if x[1] else None for x in results_full]\n",
    "df_res['dml_pl_p_val'] = [x[1][5].refutation_result['p_value'] if x[1] else None for x in results_full]\n",
    "df_res['dml_pl_is_statistically_significant'] = [x[1][5].refutation_result['is_statistically_significant'] if x[1] else None for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ab8dc-d8f8-49fd-98ae-b7816fcf8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['modifiers'] = [x[2] for x in results_full]\n",
    "df_res['confounders'] = [x[3] for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015bc0f-c48f-4359-98ad-f9099f0d1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['backdoor_var'] = [x[4] for x in results_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612bffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
